{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from attacks.minimization import *\n",
    "import json\n",
    "import os\n",
    "import torchattacks\n",
    "import time\n",
    "\n",
    "from _testbed_utils import original_dataloader, get_data\n",
    "from models import create_simple_neural_network, create_dynamic_neural_network, create_dynamic_dm_neural_network\n",
    "from dataloader_ids import load_and_prepare_data\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(dataset_key, encoding_key, multiclass, seed=42):\n",
    "    train_loader, _, test_loader, test_indices, input_dim, output_dim, y_mapping, scaler, _ = load_and_prepare_data(dataset_key, encoding_key, multiclass, random_state=seed)\n",
    "    return train_loader, test_loader, test_indices, input_dim, output_dim, y_mapping, scaler\n",
    "\n",
    "def extract_hidden_dims(params):\n",
    "    hidden_dims = []\n",
    "    for key, value in params.items():\n",
    "        if key.startswith(\"hidden_dim_layer_\"):\n",
    "            hidden_dims.append(value)\n",
    "\n",
    "    # Sort by layer index in case keys are unordered\n",
    "    hidden_dims = [v for k, v in sorted((key, value) for key, value in params.items() if key.startswith(\"hidden_dim_layer_\"))]\n",
    "    return hidden_dims\n",
    "\n",
    "def get_and_create_model(dataset, encoding, multiclass, input_dim, output_dim):\n",
    "    \n",
    "    best_params_fp = f\"results/model_discovery/{dataset}/{encoding}/best_params.json\"\n",
    "\n",
    "    with open(best_params_fp, \"r\") as f:\n",
    "        best_params = json.load(f)\n",
    "        hidden_dims = extract_hidden_dims(best_params)\n",
    "        learning_rate = best_params[\"lr\"]\n",
    "        dropout_rate = best_params[\"dropout\"]\n",
    "    \n",
    "    if encoding == 'DM':\n",
    "        model, _, _ = create_dynamic_dm_neural_network(\n",
    "            input_dim=input_dim,\n",
    "            output_dim=output_dim,\n",
    "            multiclass=multiclass,\n",
    "            hidden_dims=hidden_dims,\n",
    "            optimizer=\"adam\",\n",
    "            lr=learning_rate,\n",
    "            dropout_rate=dropout_rate\n",
    "        )\n",
    "    else:\n",
    "        model, _, _ = create_dynamic_neural_network(\n",
    "            input_dim=input_dim,\n",
    "            output_dim=output_dim,\n",
    "            multiclass=multiclass,\n",
    "            hidden_dims=hidden_dims,\n",
    "            optimizer=\"adam\",\n",
    "            lr=learning_rate,\n",
    "            dropout_rate=dropout_rate\n",
    "        )\n",
    "    model = model.to(device)\n",
    "    return model\n",
    "\n",
    "def get_latest_model_state(dataset, encoding, mode, multiclass, input_dim, output_dim):\n",
    "    model = get_and_create_model(dataset, encoding, multiclass, input_dim, output_dim)\n",
    "\n",
    "    model_dir = f\"trained_models/{dataset}/{encoding}/{mode}/\"\n",
    "\n",
    "    model_files = [f for f in os.listdir(model_dir) if f.endswith(\".pth\")]\n",
    "    if not model_files:\n",
    "        raise FileNotFoundError(\"No model files found\")\n",
    "    latest_model = max(model_files, key=lambda f: os.path.getmtime(os.path.join(model_dir, f)))\n",
    "    latest_model_path = os.path.join(model_dir, latest_model)\n",
    "    print(f\"Loading checkpoint: {latest_model_path}\")\n",
    "\n",
    "    if encoding == 'DM':\n",
    "        state = torch.load(latest_model_path, map_location='cpu')\n",
    "        model.load_state_dict(state, strict=False)\n",
    "    else:\n",
    "        model.load_state_dict(torch.load(latest_model_path, map_location=torch.device('cpu')))\n",
    "        \n",
    "    model.eval()\n",
    "    return model                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_and_data(dataset, encoding, training_mode, multiclass, seed):\n",
    "    \"\"\"\n",
    "    Load the trained model and test data for a given dataset and encoding.\n",
    "\n",
    "    Args:\n",
    "      dataset (str): dataset name (e.g., 'mirai').\n",
    "      encoding (str): feature encoding type ('Raw', 'DM', etc.).\n",
    "      multiclass (bool): whether the task is multiclass.\n",
    "\n",
    "    Returns:\n",
    "      model (torch.nn.Module): loaded PyTorch model in eval mode.\n",
    "      all_data (torch.Tensor): concatenated test inputs (n_samples, n_features).\n",
    "      all_labels (torch.Tensor): concatenated test labels (n_samples,).\n",
    "      df_clean (pd.DataFrame): clean test inputs as a DataFrame.\n",
    "    \"\"\"\n",
    "    # training_mode = 'baseline_True' if encoding in ('DM', 'Stats') else 'baseline'\n",
    "    _, test_loader, _, input_dim, output_dim, _, scaler = get_data(\n",
    "        dataset, encoding, multiclass, seed=seed\n",
    "    )\n",
    "    model = get_latest_model_state(\n",
    "        dataset, encoding, training_mode, multiclass, input_dim, output_dim\n",
    "    ).to(device)\n",
    "    model.eval()\n",
    "\n",
    "    all_data, all_labels = [], []\n",
    "    for x, y in test_loader:\n",
    "        all_data.append(x)\n",
    "        all_labels.append(y)\n",
    "\n",
    "    \n",
    "    all_data = torch.cat(all_data, dim=0).to(device)\n",
    "    all_labels = torch.cat(all_labels, dim=0).to(device)\n",
    "\n",
    "    df_clean = pd.DataFrame(\n",
    "        all_data.cpu().numpy(),\n",
    "        columns=[f\"feature_{i}\" for i in range(all_data.size(1))]\n",
    "    )\n",
    "    print(df_clean.shape)\n",
    "    return model, all_data, all_labels, df_clean\n",
    "\n",
    "def perform_attack(model, data, labels, method, params):\n",
    "    \"\"\"\n",
    "    Generate adversarial examples using a specified attack.\n",
    "\n",
    "    Args:\n",
    "      model (torch.nn.Module): the target model.\n",
    "      data (torch.Tensor): clean inputs (n_samples, n_features).\n",
    "      labels (torch.Tensor): true labels (n_samples,).\n",
    "      method (str): one of 'fgsm', 'cw', 'deepfool', 'jsma'.\n",
    "      params (dict): attack-specific parameters:\n",
    "        - fgsm: {'eps': float}\n",
    "        - cw: {'c': float, 'kappa': float}\n",
    "        - jsma: {'theta': float, 'gamma': float}\n",
    "        - deepfool: {}\n",
    "    Returns:\n",
    "      adv_np (np.ndarray): adversarial examples as NumPy array.\n",
    "    \"\"\"\n",
    "    if method == 'fgsm':\n",
    "        atk = torchattacks.FGSM(model, eps=params['eps'])\n",
    "        adv = atk(data, labels)\n",
    "    elif method == 'cw':\n",
    "        atk = torchattacks.CW(model, c=params['c'], kappa=params['kappa'], steps=100, lr=0.05)\n",
    "        adv = atk(data, labels)\n",
    "    elif method == 'deepfool':\n",
    "        atk = torchattacks.DeepFool(model, overshoot=params['overshoot'], steps=20)\n",
    "        adv = atk(data, labels)\n",
    "    elif method == 'jsma':\n",
    "        atk = torchattacks.JSMA(model, theta=params['theta'], gamma=params['gamma'])\n",
    "        adv = atk(data, labels)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown attack: {method}\")\n",
    "    return adv.cpu().numpy()\n",
    "\n",
    "def fraction_clipped(adv_np):\n",
    "    \"\"\"\n",
    "    Compute the fraction of features that are exactly 0 or 1 after clipping.\n",
    "\n",
    "    Args:\n",
    "      adv_np (np.ndarray): adversarial inputs (n_samples, n_features).\n",
    "\n",
    "    Returns:\n",
    "      float: fraction of entries equal to 0 or 1.\n",
    "    \"\"\"\n",
    "    n, f = adv_np.shape\n",
    "    clipped = np.logical_or(adv_np == 0, adv_np == 1).sum()\n",
    "    return clipped / (n * f)\n",
    "\n",
    "def evaluate(model, adv_np, df_clean, labels, encoding):\n",
    "    \"\"\"\n",
    "    Evaluate model performance and perturbation norms on adversarial data.\n",
    "\n",
    "    Args:\n",
    "      model (torch.nn.Module): the target model.\n",
    "      adv_np (np.ndarray): adversarial inputs (n_samples, n_features).\n",
    "      df_clean (pd.DataFrame): clean inputs as DataFrame.\n",
    "      labels (torch.Tensor): true labels (n_samples,).\n",
    "      encoding (str): 'Raw' or other encoding type.\n",
    "\n",
    "    Returns:\n",
    "      acc (float): accuracy.\n",
    "      prec (float): weighted precision.\n",
    "      rec (float): weighted recall.\n",
    "      f1 (float): weighted F1 score.\n",
    "      mean_norm (float): mean L2 (raw) or Frobenius (DM) perturbation norm.\n",
    "      clip_frac (float): fraction of features clipped to 0 or 1.\n",
    "    \"\"\"\n",
    "    X_adv_t = torch.from_numpy(adv_np).float().to(device)\n",
    "    outputs = model(X_adv_t)\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "    y_true = labels.cpu().numpy()\n",
    "    y_pred = preds.cpu().numpy()\n",
    "    acc  = (y_pred == y_true).mean()\n",
    "    prec = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    rec  = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    f1   = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "    # Compute clean norms for each norm type\n",
    "    clean_linf = np.linalg.norm(df_clean.values, ord=np.inf, axis=1)\n",
    "    clean_l2   = np.linalg.norm(df_clean.values, ord=2, axis=1)\n",
    "    clean_l0   = np.linalg.norm(df_clean.values, ord=0, axis=1)\n",
    "\n",
    "    # Compute median reference for each norm\n",
    "    ref_linf = np.median(clean_linf)\n",
    "    ref_l2   = np.median(clean_l2)\n",
    "    ref_l0   = np.median(clean_l0)\n",
    "\n",
    "    # Compute the perturbation delta\n",
    "    delta = adv_np - df_clean.values\n",
    "\n",
    "    # Compute mean norms for perturbation\n",
    "    linf_mean_norm = np.linalg.norm(delta, ord=np.inf, axis=1).mean()\n",
    "    l2_mean_norm   = np.linalg.norm(delta, ord=2, axis=1).mean()\n",
    "    l0_mean_norm   = np.linalg.norm(delta, ord=0, axis=1).mean()\n",
    "\n",
    "    # Compute percentage changes\n",
    "    pct_change_linf = 100 * linf_mean_norm / ref_linf\n",
    "    pct_change_l2   = 100 * l2_mean_norm   / ref_l2\n",
    "    pct_change_l0   = 100 * l0_mean_norm   / ref_l0\n",
    "\n",
    "    mean_norms = {\n",
    "        'linf': linf_mean_norm,\n",
    "        'l2': l2_mean_norm,\n",
    "        'l0': l0_mean_norm\n",
    "    }\n",
    "    pct_changes = {\n",
    "        'linf': pct_change_linf,\n",
    "        'l2': pct_change_l2,\n",
    "        'l0': pct_change_l0\n",
    "    }\n",
    "\n",
    "    clip_frac = fraction_clipped(adv_np)\n",
    "    return acc, prec, rec, f1, mean_norms, clip_frac, pct_changes\n",
    "\n",
    "def sweep_attack(dataset, attack, encoding, model, all_data, all_labels, df_clean):\n",
    "    \"\"\"\n",
    "    Run attack over various parameter combinations and collect metrics.\n",
    "    \n",
    "    Args:\n",
    "      attack (str): attack type ('fgsm', 'cw', 'jsma', etc.).\n",
    "      dataset (str): dataset name.\n",
    "      encoding (str): feature encoding type.\n",
    "      training_mode (str): how the model was trained.\n",
    "      multiclass (bool): multiclass flag.\n",
    "      seed (int): random seed for reproducibility.\n",
    "    \n",
    "    Returns:\n",
    "      norms (list of float): mean perturbation norms.\n",
    "      clips (list of float): clipping fractions.\n",
    "      pcts (list of float): percentage changes.\n",
    "      accs (list of float): accuracies.\n",
    "      precisions (list of float): precision scores.\n",
    "      recalls (list of float): recall scores.\n",
    "      f1s (list of float): F1 scores.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize result lists\n",
    "    results = {\n",
    "        'accs': [], 'precisions': [], 'recalls': [], 'f1s': [],\n",
    "        'norms_linf': [], 'norms_l2': [], 'norms_l0': [],\n",
    "        'pcts_linf': [], 'pcts_l2': [], 'pcts_l0': [],\n",
    "        'clips': []\n",
    "    }\n",
    "    if dataset == 'unsw-nb15':\n",
    "        attack_params = {\n",
    "            'fgsm': [{'eps': eps} for eps in [0.0005, 0.001, 0.01, 0.05, 0.1, 0.5, 1]],\n",
    "            'jsma': [\n",
    "                {'theta': theta, 'gamma': gamma}\n",
    "                for theta in [0.0005, 0.001, 0.01, 0.05, 0.1, 0.5, 1]\n",
    "                for gamma in [0.1]\n",
    "            ],\n",
    "            'cw': [\n",
    "                {'c': c, 'kappa': kappa}\n",
    "                for c in [0.001, 0.01, 0.05, 0.1, 0.5, 1, 10, 100, 1000]\n",
    "                for kappa in [0]\n",
    "            ]\n",
    "        }\n",
    "    elif dataset == 'mirai':\n",
    "        attack_params = {\n",
    "            'fgsm': [{'eps': eps} for eps in [0.0005, 0.001, 0.01, 0.05, 0.1, 0.5, 1]],\n",
    "            'jsma': [\n",
    "                {'theta': theta, 'gamma': gamma}\n",
    "                for theta in [0.0005, 0.001, 0.01, 0.05, 0.1, 0.5, 1]\n",
    "                for gamma in [0.1]\n",
    "            ],\n",
    "            'cw': [\n",
    "                {'c': c, 'kappa': kappa}\n",
    "                for c in [0.001, 0.01, 0.05, 0.1, 0.5, 1, 10, 100, 1000]\n",
    "                for kappa in [0]\n",
    "            ]\n",
    "        }    \n",
    "\n",
    "    # Fallback for unknown attack types\n",
    "    if attack not in attack_params:\n",
    "        raise ValueError(f\"Attack type '{attack}' not supported. Supported types: {list(attack_params.keys())}\")\n",
    "    \n",
    "    print(f\"Running attack: {attack}\")\n",
    "\n",
    "    # Run attacks with appropriate parameters\n",
    "    for i, params in enumerate(attack_params[attack]):\n",
    "        start_time = time.time()\n",
    "        print(f\"    - ({i+1}/{len(attack_params[attack])}) Running {attack} with parameters: {params}\")\n",
    "        adv = perform_attack(\n",
    "            model, all_data, all_labels,\n",
    "            method=attack,\n",
    "            params=params\n",
    "        )\n",
    "        \n",
    "        # Evaluate and store results\n",
    "        metrics = evaluate(model, adv, df_clean, all_labels, encoding)\n",
    "        acc, prec, rec, f1, mns, cf, pct_changes = metrics\n",
    "\n",
    "        \n",
    "        results['accs'].append(acc)\n",
    "        results['precisions'].append(prec)\n",
    "        results['recalls'].append(rec)\n",
    "        results['f1s'].append(f1)\n",
    "        results['norms_linf'].append(mns['linf'])\n",
    "        results['norms_l2'].append(mns['l2'])\n",
    "        results['norms_l0'].append(mns['l0'])\n",
    "        results['pcts_linf'].append(pct_changes['linf'])\n",
    "        results['pcts_l2'].append(pct_changes['l2'])\n",
    "        results['pcts_l0'].append(pct_changes['l0'])\n",
    "        results['clips'].append(cf)\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "        print(f\"    - Time taken: {elapsed_time:.2f} seconds\")\n",
    "    \n",
    "    return attack_params, results\n",
    "\n",
    "def sweep_defensive_attack(dataset, attack, encoding, model, all_data, all_labels, df_clean, breakpoints=(3.0, 10.0, 20.0)):\n",
    "    \"\"\"\n",
    "    Run attack with specific parameters against defensively trained models.\n",
    "    \n",
    "    Args:\n",
    "      dataset (str): dataset name ('unsw-nb15' or 'mirai').\n",
    "      attack (str): attack type ('fgsm', 'cw', 'jsma').\n",
    "      encoding (str): feature encoding type ('dm', 'stats', 'raw').\n",
    "      model: the defensively trained model to attack.\n",
    "      all_data: test data for attacking.\n",
    "      all_labels: test labels.\n",
    "      df_clean: clean dataframe for evaluation.\n",
    "      breakpoints (tuple): perturbation budgets to test (default: 3%, 10%, 20%).\n",
    "    \n",
    "    Returns:\n",
    "      attack_params (dict): parameters used for each attack.\n",
    "      results (dict): evaluation metrics for each attack parameter.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize result lists\n",
    "    results = {\n",
    "        'accs': [], 'precisions': [], 'recalls': [], 'f1s': [],\n",
    "        'norms_linf': [], 'norms_l2': [], 'norms_l0': [],\n",
    "        'pcts_linf': [], 'pcts_l2': [], 'pcts_l0': [],\n",
    "        'clips': []\n",
    "    }\n",
    "    \n",
    "    # Define parameter lookup dictionary\n",
    "    attack_param_lookup = {\n",
    "        'unsw-nb15': {\n",
    "            'fgsm': {\n",
    "                'DM': {3.0: 0.0020, 10.0: 0.0102, 20.0: 0.0222},\n",
    "                'Stats': {3.0: 0.0065, 10.0: 0.0232, 20.0: 0.0477},\n",
    "                'Raw': {3.0: 0.0076, 10.0: 0.0255, 20.0: 0.0514},\n",
    "            },\n",
    "            'cw': {\n",
    "                'DM': {3.0: 0.2188, 10.0: 1.7038, 20.0: 14.5477},\n",
    "                'Stats': {3.0: 0.1014, 10.0: 0.3870, 20.0: 13.0739},\n",
    "                'Raw': {3.0: 0.0984, 10.0: 1.1614, 20.0: 7.2549}\n",
    "            },\n",
    "            'jsma': {\n",
    "                'DM': {3.0: 0.0048, 10.0: 0.0294, 20.0: 0.0722},\n",
    "                'Stats': {3.0: 0.0178, 10.0: 0.0652, 20.0: 0.1576},\n",
    "                'Raw': {3.0: 0.0179, 10.0: 0.0599, 20.0: 0.1217}\n",
    "            }\n",
    "        },\n",
    "        'mirai': {\n",
    "            'fgsm': {\n",
    "                'DM': {3.0: 0.0024, 10.0: 0.0095, 20.0: 0.0196},\n",
    "                'Stats': {3.0: 0.0129, 10.0: 0.0438, 20.0: 0.0882},\n",
    "                'Raw': {3.0: 0.0147, 10.0: 0.0497, 20.0: 0.1015}\n",
    "            },\n",
    "            'cw': {\n",
    "                'DM': {3.0: 2.6329, 10.0: 6.5819, 20.0: 19.1194},\n",
    "                'Stats': {3.0: 5.7543, 10.0: 29.4873, 20.0: 362.6893},\n",
    "                'Raw': {3.0: 4.4241, 10.0: 1000, 20.0: 1000}\n",
    "            },\n",
    "            'jsma': {\n",
    "                'DM': {3.0: 0.0054, 10.0: 0.0236, 20.0: 0.0506},\n",
    "                'Stats': {3.0: 0.0346, 10.0: 0.1189, 20.0: 0.2702},\n",
    "                'Raw': {3.0: 0.0560, 10.0: 0.2099, 20.0: 0.4501}\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Generate attack parameters based on breakpoints\n",
    "    attack_params = []\n",
    "    for bp in breakpoints:\n",
    "        if attack == 'fgsm':\n",
    "            eps = attack_param_lookup[dataset][attack][encoding][bp]\n",
    "            attack_params.append({'eps': eps})\n",
    "        elif attack == 'jsma':\n",
    "            theta = attack_param_lookup[dataset][attack][encoding][bp]\n",
    "            attack_params.append({'theta': theta, 'gamma': 0.1})\n",
    "        elif attack == 'cw':\n",
    "            c = attack_param_lookup[dataset][attack][encoding][bp]\n",
    "            attack_params.append({'c': c, 'kappa': 0})\n",
    "        else:\n",
    "            raise ValueError(f\"Attack type '{attack}' not supported. Supported types: fgsm, cw, jsma\")\n",
    "    \n",
    "    print(f\"Running attack: {attack} at perturbation budgets {breakpoints}\")\n",
    "\n",
    "    # Run attacks with appropriate parameters\n",
    "    for i, params in enumerate(attack_params):\n",
    "        start_time = time.time()\n",
    "        bp = breakpoints[i]\n",
    "        print(f\"    - ({i+1}/{len(attack_params)}) Running {attack} with parameters: {params} (budget: {bp}%)\")\n",
    "        adv = perform_attack(\n",
    "            model, all_data, all_labels,\n",
    "            method=attack,\n",
    "            params=params\n",
    "        )\n",
    "        \n",
    "        # Evaluate and store results\n",
    "        metrics = evaluate(model, adv, df_clean, all_labels, encoding)\n",
    "        acc, prec, rec, f1, mns, cf, pct_changes = metrics\n",
    "        \n",
    "        results['accs'].append(acc)\n",
    "        results['precisions'].append(prec)\n",
    "        results['recalls'].append(rec)\n",
    "        results['f1s'].append(f1)\n",
    "        results['norms_linf'].append(mns['linf'])\n",
    "        results['norms_l2'].append(mns['l2'])\n",
    "        results['norms_l0'].append(mns['l0'])\n",
    "        results['pcts_linf'].append(pct_changes['linf'])\n",
    "        results['pcts_l2'].append(pct_changes['l2'])\n",
    "        results['pcts_l0'].append(pct_changes['l0'])\n",
    "        results['clips'].append(cf)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "        print(f\"    - Time taken: {elapsed_time:.2f} seconds\")\n",
    "        print(f\"    - Results: Acc={acc:.4f}, Prec={prec:.4f}, Rec={rec:.4f}, F1={f1:.4f}, L2 Norm={mns['l2']:.4f}, Relative L2={pct_changes['l2']:.4f}\")\n",
    "    \n",
    "    return attack_params, results\n",
    "\n",
    "def plot_robustness_with_clipping(epsilons, norms, accs, clips, encoding):\n",
    "    \"\"\"\n",
    "    Plot accuracy vs. mean perturbation norm with clipping fraction overlay.\n",
    "\n",
    "    Args:\n",
    "      epsilons (list of float): FGSM ε values (for annotation).\n",
    "      norms (list of float): mean perturbation norms.\n",
    "      accs (list of float): accuracies.\n",
    "      clips (list of float): clipping fractions.\n",
    "      encoding (str): encoding name for title.\n",
    "    \"\"\"\n",
    "    fig, ax1 = plt.subplots(figsize=(6,4))\n",
    "    ax1.plot(norms, accs, 'b-o', label='Accuracy')\n",
    "    ax1.set_xlabel('Mean perturbation norm')\n",
    "    ax1.set_ylabel('Accuracy', color='b')\n",
    "    ax1.tick_params(axis='y', labelcolor='b')\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(norms, clips, 'r-s', label='Clipped fraction')\n",
    "    ax2.set_ylabel('Fraction clipped', color='r')\n",
    "    ax2.tick_params(axis='y', labelcolor='r')\n",
    "\n",
    "    plt.title(f'FGSM Robustness + Clipping ({encoding})')\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def norms_table(norm_objects, epsilons, encodings):\n",
    "    data = {}\n",
    "    for encoding, norms in zip(encodings, norm_objects):\n",
    "        data[encoding] = norms\n",
    "    df = pd.DataFrame(data, index=epsilons).T\n",
    "    return df\n",
    "\n",
    "def pct_change_table(pct_changes, epsilons, encodings):\n",
    "    data = {}\n",
    "    for encoding, norms in zip(encodings, pct_changes):\n",
    "        data[encoding] = norms\n",
    "    df = pd.DataFrame(data, index=epsilons).T\n",
    "    return df\n",
    "\n",
    "def metrics_table(metrics, epsilons, encodings):\n",
    "    data = {}\n",
    "    for encoding, metric in zip(encodings, metrics):\n",
    "        data[encoding] = metric\n",
    "    df = pd.DataFrame(data, index=epsilons).T\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Configuration\n",
    "DATASETS = ['mirai', 'unsw-nb15']\n",
    "ENCODINGS = ['DM', 'Stats', 'Raw']\n",
    "TRAINING_MODES = ['baseline', 'pgd', 'mart', 'trades']\n",
    "ATTACK_TYPES = ['fgsm', 'cw', 'jsma'] \n",
    "EPS_VALUES = [0.001, 0.01, 0.1] \n",
    "MULTICLASS = [False, True]\n",
    "SEED = 42\n",
    "\n",
    "BASE_DIR = 'results/attack_sweep'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(base_dir=BASE_DIR, seed=SEED):\n",
    "\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    os.makedirs(base_dir, exist_ok=True)\n",
    "\n",
    "    # Total experiments counter\n",
    "    total_experiments = (\n",
    "        len(DATASETS) * \n",
    "        len(ENCODINGS) * \n",
    "        (1 + (len(TRAINING_MODES) - 1) * len(EPS_VALUES)) * \n",
    "        len(ATTACK_TYPES)\n",
    "    )\n",
    "    completed = 0\n",
    "    \n",
    "    # Log file for tracking progress\n",
    "    log_file = os.path.join(base_dir, f\"experiment_log_{timestamp}.txt\")\n",
    "    with open(log_file, 'a') as f:\n",
    "        f.write(f\"Starting experiment run at {datetime.now()}\\n\")\n",
    "        f.write(f\"Total experiments to run: {total_experiments}\\n\")\n",
    "\n",
    "    try:\n",
    "        for dataset, multiclass in zip(DATASETS, MULTICLASS):\n",
    "            # Create dataset directory\n",
    "            dataset_dir = os.path.join(base_dir, dataset)\n",
    "            os.makedirs(dataset_dir, exist_ok=True)\n",
    "            \n",
    "            for encoding in ENCODINGS:\n",
    "                # First handle baseline (no eps variations)\n",
    "                baseline_dir = os.path.join(dataset_dir, \"baseline\")\n",
    "                os.makedirs(baseline_dir, exist_ok=True)\n",
    "                \n",
    "                for attack in ATTACK_TYPES:\n",
    "                    experiment_id = f\"{dataset}_{encoding}_{attack}\"\n",
    "\n",
    "                    print(f\"Running experiment {completed+1}/{total_experiments}: {experiment_id}\")\n",
    "\n",
    "                    _training_mode = 'baseline'\n",
    "                        \n",
    "                    model, all_data, all_labels, df_clean = load_model_and_data(\n",
    "                        dataset, encoding, _training_mode, multiclass, seed\n",
    "                    )\n",
    "                \n",
    "                    start_time = time.time()\n",
    "                    attack_params, results = sweep_attack(\n",
    "                        dataset=dataset,\n",
    "                        attack=attack,\n",
    "                        encoding=encoding,\n",
    "                        model=model,\n",
    "                        all_data=all_data,\n",
    "                        all_labels=all_labels,\n",
    "                        df_clean=df_clean\n",
    "                    )\n",
    "                    \n",
    "                    print(results)\n",
    "\n",
    "                    # Create DataFrame and save to CSV\n",
    "                    df = pd.DataFrame({\n",
    "                        'parameter_index': range(len(results['accs'])),\n",
    "                        'attack_params': [str(params) for params in attack_params[attack]],\n",
    "                        'norm_linf': results['norms_linf'],\n",
    "                        'norm_l2': results['norms_l2'],\n",
    "                        'norm_l0': results['norms_l0'],\n",
    "                        'clip': results['clips'],\n",
    "                        'pct_change_linf': results['pcts_linf'],\n",
    "                        'pct_change_l2': results['pcts_l2'],\n",
    "                        'pct_change_l0': results['pcts_l0'],\n",
    "                        'accuracy': results['accs'],\n",
    "                        'precision': results['precisions'],\n",
    "                        'recall': results['recalls'],\n",
    "                        'f1': results['f1s']\n",
    "                    })\n",
    "                    \n",
    "                    output_file = os.path.join(baseline_dir, f\"{encoding}_{attack}.csv\")\n",
    "                    df.to_csv(output_file, index=False)\n",
    "                    \n",
    "                    # Log completion\n",
    "                    elapsed = time.time() - start_time\n",
    "                    with open(log_file, 'a') as f:\n",
    "                        f.write(f\"Completed {experiment_id} in {elapsed:.2f} seconds\\n\")\n",
    "                        f.write(f\"Progress: {completed}/{total_experiments}\\n\")\n",
    "                    \n",
    "                # Handle other training modes with eps variations\n",
    "                for training_mode in TRAINING_MODES:\n",
    "\n",
    "                    if training_mode == 'baseline':\n",
    "                        continue  # Already handled\n",
    "                    \n",
    "                    # Create training mode directory\n",
    "                    training_dir = os.path.join(dataset_dir, training_mode)\n",
    "                    os.makedirs(training_dir, exist_ok=True)\n",
    "                    \n",
    "                    for eps in EPS_VALUES:\n",
    "                        model_name = f\"{training_mode}_eps{eps}\"\n",
    "                        \n",
    "                        # Create eps-specific directory\n",
    "                        eps_dir = os.path.join(training_dir, f\"eps{eps}\")\n",
    "                        os.makedirs(eps_dir, exist_ok=True)\n",
    "                        \n",
    "                        for attack in ATTACK_TYPES:\n",
    "\n",
    "                            experiment_id = f\"{dataset}_{encoding}_{attack}\"\n",
    "                            \n",
    "                            print(f\"Running experiment {completed+1}/{total_experiments}: {experiment_id}\")\n",
    "                            with open(log_file, 'a') as f:\n",
    "                                f.write(f\"Starting {experiment_id} at {datetime.now()}\\n\")\n",
    "                            \n",
    "\n",
    "                            model, all_data, all_labels, df_clean = load_model_and_data(\n",
    "                                dataset, encoding, model_name, multiclass, SEED\n",
    "                            )\n",
    "                        \n",
    "                            start_time = time.time()\n",
    "    \n",
    "                            attack_params, results = sweep_defensive_attack(\n",
    "                                dataset=dataset,\n",
    "                                attack=attack,\n",
    "                                encoding=encoding,\n",
    "                                model=model,\n",
    "                                all_data=all_data,\n",
    "                                all_labels=all_labels,\n",
    "                                df_clean=df_clean,\n",
    "                                breakpoints=(3.0, 10.0, 20.0)  # Default, can be omitted\n",
    "                            )\n",
    "                            print(results)\n",
    "                            print(attack_params)\n",
    "                            \n",
    "                            # Create DataFrame and save to CSV\n",
    "                            df = pd.DataFrame({\n",
    "                                'parameter_index': range(len(results['accs'])),\n",
    "                                'attack_params': [str(params) for params in attack_params], # [str(params) for params in attack_params[attack]],\n",
    "                                'norm_linf': results['norms_linf'],\n",
    "                                'norm_l2': results['norms_l2'],\n",
    "                                'norm_l0': results['norms_l0'],\n",
    "                                'clip': results['clips'],\n",
    "                                'pct_change_linf': results['pcts_linf'],\n",
    "                                'pct_change_l2': results['pcts_l2'],\n",
    "                                'pct_change_l0': results['pcts_l0'],\n",
    "                                'accuracy': results['accs'],\n",
    "                                'precision': results['precisions'],\n",
    "                                'recall': results['recalls'],\n",
    "                                'f1': results['f1s']\n",
    "                            })\n",
    "                    \n",
    "                            output_file = os.path.join(eps_dir, f\"{encoding}_{attack}.csv\")\n",
    "                            df.to_csv(output_file, index=False)\n",
    "                            \n",
    "                            # Log completion time\n",
    "                            elapsed = time.time() - start_time\n",
    "                            with open(log_file, 'a') as f:\n",
    "                                f.write(f\"Completed {experiment_id} in {elapsed:.2f} seconds\\n\")\n",
    "                                f.write(f\"Progress: {completed}/{total_experiments}\\n\")\n",
    "                            \n",
    "        print(f\"All experiments completed! Data saved to {base_dir}\")\n",
    "        with open(log_file, 'a') as f:\n",
    "            f.write(f\"All experiments completed at {datetime.now()}\\n\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        # Log the error\n",
    "        with open(log_file, 'a') as f:\n",
    "            f.write(f\"ERROR at {datetime.now()}: {str(e)}\\n\")\n",
    "        print(f\"Error occurred: {str(e)}\")\n",
    "        print(f\"Experiment progress saved: {experiment_id}.\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(base_dir=BASE_DIR, seed=SEED)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
